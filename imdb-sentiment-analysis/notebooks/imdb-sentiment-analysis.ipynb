{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e19bde6-93c1-4c86-a97f-6b5f40b4ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af86f463-b2be-4d35-a9de-17e267a26d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import os\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac53108f-dbab-4899-beae-63f0e1226924",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c21d102-31d7-476b-ae1a-e61caf8a8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import get_datasets, get_dataloaders\n",
    "from model import get_tokenizer, get_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b34ba62-6322-4775-b091-c5764fbc5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '../data/'\n",
    "ds = None\n",
    "\n",
    "if not os.path.exists(data_directory):\n",
    "    ds = load_dataset(\"stanfordnlp/imdb\")\n",
    "    ds.save_to_disk(data_directory)\n",
    "else:\n",
    "    ds = load_from_disk(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a611af71-85fe-42e6-9a28-d45b32e89527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Running on {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd5cbe-00dd-494f-bc8c-60f3daefa33a",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a75d3eae-7749-423e-a900-7ca9d878acad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test', 'unsupervised'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17a618e-b3e7-4df5-9281-e74e19d123ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d1c5486-7d45-48fd-9553-1692946791c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface dataset already has train test split of data \n",
    "\n",
    "train_df = ds['train'].to_pandas()\n",
    "test_df = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd187bc-d505-43e8-8b62-e96e79007c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d30015-71b6-4350-90fa-c53d482601a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b362ab8-e0b6-4433-a57c-e39a993656c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12500\n",
       "1    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21e60bc6-b204-4874-a21f-4fbb653462e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12500\n",
       "1    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "885bb8cb-8cfd-41c7-95da-743bc58c7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the class distribution is good. No need to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ee36e6e-fc16-442e-8451-89b4ea6f45e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6fbaf7a-de88-40b6-80eb-51aa83d17422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I love sci-fi and am willing to put up with a ...      0\n",
       "1  Worth the entertainment value of a rental, esp...      0\n",
       "2  its a totally average film with a few semi-alr...      0\n",
       "3  STAR RATING: ***** Saturday Night **** Friday ...      0\n",
       "4  First off let me say, If you haven't enjoyed a...      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4901bb8e-727d-4a88-9bae-f2b42ecdd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_len(row):\n",
    "    ''' Function to get the length of sentence based on space as delimiter\n",
    "    Not perfect function but decent for approximation\n",
    "    '''\n",
    "    sentence = row['text']\n",
    "    return len(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c470538-0ea4-40a1-8784-f14f4ba71791",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text_len'] = train_df.apply(get_sentence_len, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fea0caf-dc8e-41ef-8d2e-df9fa09e31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['text_len'] = test_df.apply(get_sentence_len, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72b2ae77-2c05-4d64-994e-cda8c53715f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       233.776720\n",
       "std        173.715418\n",
       "min         10.000000\n",
       "25%        127.000000\n",
       "50%        174.000000\n",
       "75%        284.000000\n",
       "max       2470.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.text_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fac02bd4-f14b-4354-b5b2-b94e7e3c2142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       228.515160\n",
       "std        168.866127\n",
       "min          4.000000\n",
       "25%        126.000000\n",
       "50%        172.000000\n",
       "75%        277.000000\n",
       "max       2278.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.text_len.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b86cb-f575-4cf7-975d-e7a88a4ca952",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7860ad9-d5cc-4182-b075-0cf8fb0f6914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "tokenizer_obj = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67ab01f1-5f67-473c-82bd-7c97754e5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pytorch datasets\n",
    "train_dataset = get_datasets(train_df['text'].to_list(), train_df['label'].to_list(), tokenizer_obj, max_length=512)\n",
    "test_dataset = get_datasets(test_df['text'].to_list(), test_df['label'].to_list(), tokenizer_obj, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73f0b5e7-ee40-42c5-bf8d-454f59b87f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pytorch dataloaders\n",
    "train_dataloader = get_dataloaders(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = get_dataloaders(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adee6ca8-ef6f-416e-a0ae-6b57b42285cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 512]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# check dataloader \n",
    "data_iter = iter(train_dataloader)\n",
    "sample = next(data_iter)\n",
    "print(sample['input_ids'].shape, sample['attention_mask'].shape, sample['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84fa74d1-329f-4f52-b2f3-dc9e6c528ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2003,  ...,     0,     0,     0],\n",
       "         [  101,  2023,  3185,  ...,     0,     0,     0],\n",
       "         [  101,  1996,  2034,  ...,  2021,  2012,   102],\n",
       "         ...,\n",
       "         [  101, 10889,  2204,  ...,     0,     0,     0],\n",
       "         [  101, 21877, 28210,  ...,     0,     0,     0],\n",
       "         [  101,  2023,  2003,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'num_tokens': tensor([ 80,  74, 510, 368, 510, 211, 161, 248]),\n",
       " 'label': tensor([1, 1, 0, 1, 1, 1, 0, 0])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3e3f3-dde6-4881-8f57-1f2ea7d7aee6",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c30a8b1-e554-49c3-887a-e67795dbd8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = get_pretrained_model(num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d757789-dafc-4004-87dd-3792aa20d772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a37b6b9-1e3a-448d-b0a6-63269ae7b3ba",
   "metadata": {},
   "source": [
    "### Initialize Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e68a43e-863b-47b0-86a1-08d5771c8576",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "momentum = 0.9\n",
    "num_epochs = 2\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdd05873-84da-4863-a585-982e639ba746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training steps in each epoch: 390\n"
     ]
    }
   ],
   "source": [
    "num_total_steps = math.ceil(len(train_dataloader) // batch_size)\n",
    "print(f'Total number of training steps in each epoch: {num_total_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0246c0-a9a1-4a0f-a5e9-f9114fa89b92",
   "metadata": {},
   "source": [
    "### Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c76972da-777a-4b1a-89a8-7f02d1050494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss(outputs, labels):\n",
    "#     # outputs: raw logits from the model (shape: [batch_size, 1])\n",
    "#     # labels: binary labels (shape: [batch_size], values: 0 or 1)\n",
    "#     loss_fn = nn.BCEWithLogitsLoss()\n",
    "#     outputs = outputs.view(-1)  # ensure shape [batch_size]\n",
    "#     labels = labels.float()     # convert labels to float\n",
    "#     loss = loss_fn(outputs, labels)\n",
    "#     return loss\n",
    "\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, parameter=None):\n",
    "        super().__init__()\n",
    "        self.parameter = parameter # Example of a parameter\n",
    "\n",
    "    def forward(self, pred_logits, target, num_tokens):\n",
    "        # Implement your custom loss logic here\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        pred_logits = pred_logits.view(-1)\n",
    "        target = target.float()\n",
    "        loss = loss_fn(pred_logits, target)\n",
    "        \n",
    "        if self.parameter is not None:\n",
    "            loss += torch.sum(self.parameter * (num_tokens)/512)\n",
    "        return loss\n",
    "\n",
    "custom_loss = CustomLoss(parameter=0.01)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b41461f-7086-43b2-88d0-3a9aa62f9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4009, grad_fn=<MseLossBackward0>)\n",
      "Epoch: 0/2, Step: 0/390, Training Loss: 0.7412158250808716\n",
      "tensor(0.3851, grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1/2, Step: 0/390, Training Loss: 0.7178337574005127\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for step_num, input_encoding in enumerate(train_dataloader):\n",
    "        input_ids = input_encoding['input_ids']\n",
    "        attention_masks = input_encoding['attention_mask']\n",
    "        labels = input_encoding['label']\n",
    "        num_tokens = input_encoding['num_tokens']\n",
    "        \n",
    "        preds = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "        print(preds.loss)\n",
    "        loss = custom_loss(preds.logits, labels, num_tokens)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step_num%10 == 0:\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Step: {step_num}/{num_total_steps}, Training Loss: {loss.item()}\")\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd67c69-778e-4e6e-9b00-27ec5bf8b781",
   "metadata": {},
   "source": [
    "### Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c2960f0-e6f4-4f19-bd15-42c06030fbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 1, 0, 0, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for step_num, input_encoding in enumerate(test_dataloader):\n",
    "        input_ids = input_encoding['input_ids']\n",
    "        attention_masks = input_encoding['attention_mask']\n",
    "        labels = input_encoding['label']\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        print(labels)\n",
    "        print(preds)\n",
    "        print((labels == preds).sum())\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309defb-e1a8-44c5-b61c-23a8baa21e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
